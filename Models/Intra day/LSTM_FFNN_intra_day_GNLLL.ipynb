{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "LSTM_FFNN_intra_day_GNLLL.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTik27Ivsp_t"
      },
      "source": [
        "LSTM on past power data to predict power 1, 2 and 3 hours ahead"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlCEJL0S9FXn"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dkq1A7bDcdXU"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import statistics as stat\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Import pytorch utilities\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fS7kKpElcdXY"
      },
      "source": [
        "x_train = pd.read_csv('windforecasts_wf1.csv', index_col='date')\n",
        "y_train = pd.read_csv('train.csv')\n",
        "# just consider the wind farm 1"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFzo9b-acdXa"
      },
      "source": [
        "# Brainstorm\n",
        "# One metric for 24 hs and other for 48 hs ?\n",
        "# 0) Check which wind farm to take before working on wf 1\n",
        "# 0) calculating the MAE for AR-3  -> Baseline RMSE (Confidence interval?)\n",
        "# 1) Making a prediction based on wp1 using LSTM\n",
        "# 2) Metric for evaluating the model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsmkBZhvOydj"
      },
      "source": [
        "y_train['date'] = pd.to_datetime(y_train.date, format= '%Y%m%d%H')\n",
        "y_train.index = y_train['date'] \n",
        "y_train.drop('date', inplace = True, axis = 1)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "NXBEkeX6Tt4S",
        "outputId": "3889fe68-6ced-4977-b2b0-584c00e659dc"
      },
      "source": [
        "# Plot heatmap of missing data\n",
        "ALL_TIME =  pd.DataFrame(index=pd.date_range(y_train.index[0],y_train.index[-1], freq='H')) \n",
        "plt.figure(figsize = (12,8))\n",
        "sns.heatmap(y_train.join(ALL_TIME, how = 'outer').isna())  #['2011-06-01':'2011-06-04']"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f81622e1790>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7PL788aJty2"
      },
      "source": [
        "# Select forecast data set\n",
        "x_train_update = x_train[x_train.hors<=12]\n",
        "x_train_update.index = pd.to_datetime(x_train_update.index, format= '%Y%m%d%H')\n",
        "x_train_update = x_train_update[:'2010-12-31 12']\n",
        "x_train_update['time'] = x_train_update.index + pd.to_timedelta(x_train_update.hors,\"H\")\n",
        "\n",
        "maxi=x_train_update[0:int(len(x_train_update)*0.8)+1].ws.max()\n",
        "mini=x_train_update[0:int(len(x_train_update)*0.8)+1].ws.min()\n",
        "x_train_update.ws=(x_train_update.ws-mini)/(maxi-mini)\n",
        "\n",
        "# One hot encode the wind directions\n",
        "wd_onehot = []\n",
        "\n",
        "for i in range(len(x_train_update)):\n",
        "  onehot = 12*[None]\n",
        "  sector = np.floor(x_train_update.wd[i]/30)\n",
        "  for s in range(12):\n",
        "    if sector == s:\n",
        "      onehot[s] = 1\n",
        "    else:\n",
        "      onehot[s] = 0\n",
        "  wd_onehot.append(onehot)\n",
        "  \n",
        "  \n",
        "x_train_sectors = pd.DataFrame(np.concatenate((np.reshape(x_train_update.ws.values,(len(x_train_update),1)),\n",
        "                                              wd_onehot,\n",
        "                                              np.cos(np.reshape(x_train_update.time.dt.hour.values,(len(x_train_update),1))*2*np.pi/24),\n",
        "                                              np.sin(np.reshape(x_train_update.time.dt.hour.values,(len(x_train_update),1))*2*np.pi/24),\n",
        "                                              np.cos(np.reshape(x_train_update.time.dt.dayofyear.values,(len(x_train_update),1))*2*np.pi/365),\n",
        "                                              np.sin(np.reshape(x_train_update.time.dt.dayofyear.values,(len(x_train_update),1))*2*np.pi/365)),\n",
        "                                            axis = 1),\n",
        "            columns = 'ws s1 s2 s3 s4 s5 s6 s7 s8 s9 s10 s11 s12 time_day_cos time_day_sin time_year_cos time_year_sin'.split())\n",
        "x_train_sectors.drop('s12',axis=1, inplace=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "l5dx76KscdXc"
      },
      "source": [
        "# Use only the power time series when continuous\n",
        "complete_ts = y_train[:'2011-01-01 00'] # all the data without any gaps\n",
        "input_generator = np.transpose(np.array([complete_ts.wp1]))\n",
        "length = 20 # length of the time series, PARAMETER TO TUNE"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xx8M_6rDfP_g"
      },
      "source": [
        "# define validation and training set\n",
        "\n",
        "batch_size = 8\n",
        "# input_generator = np.transpose(np.array([y_train.wp1]))\n",
        "\n",
        "# Note: TimeseriesGenerator end_index is including that index, not excluding it as it is the case in general in Python\n",
        "\n",
        "training_set = TimeseriesGenerator(input_generator, input_generator, length=length, batch_size=batch_size, shuffle = False, start_index = 0 , end_index = int(len(complete_ts)*0.8)) # 80 percent\n",
        "validation_set = TimeseriesGenerator(input_generator, input_generator, length=length, batch_size=batch_size, shuffle = False, start_index = int(len(complete_ts)*0.8)+1, end_index = len(complete_ts)-1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHg7dFwCv81O",
        "outputId": "2ea25071-1b5d-4f56-cecf-513bfb868a52"
      },
      "source": [
        "print(f'The lenght of the validation set: {len(validation_set)}')\n",
        "print(f'The lenght of the training set: {len(training_set)}')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The lenght of the validation set: 327\n",
            "The lenght of the training set: 1316\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "653bkP0gtbDB"
      },
      "source": [
        "**Creation of LSTM architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vx4ib4ApcdXd",
        "outputId": "e39536ad-3d80-4545-94fe-d4e84a66e140"
      },
      "source": [
        "class FFNN_LSTM(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FFNN_LSTM, self).__init__()\n",
        "        # input_size – The number of expected features in the input x\n",
        "        # hidden_size – The number of features in the hidden state h\n",
        "        # batch_first = False >>> input prov (seq, batch, feature)\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size = 1, \n",
        "                  hidden_size = 512,\n",
        "                     num_layers = 1,\n",
        "                         batch_first = False)\n",
        "        \n",
        "\n",
        "        self.inputLay = nn.Linear(in_features = 16,\n",
        "                               out_features = 512,\n",
        "                               bias = True)\n",
        "        \n",
        "        self.hidden_layer = nn.Linear(in_features = 512,\n",
        "                                      out_features = 512,\n",
        "                                      bias = True)\n",
        "        \n",
        "        self.combined = nn.Linear(in_features= 512+512, \n",
        "                        out_features= 512,\n",
        "                        bias = True) # should be false ?\n",
        "\n",
        "        self.output_lay_expectation = nn.Linear(in_features= 512, \n",
        "                        out_features= 1,\n",
        "                        bias = True) # should be false ?\n",
        "\n",
        "        self.output_lay_variance = nn.Linear(in_features= 512, \n",
        "                out_features= 1,\n",
        "                bias = True) # should be false ?\n",
        "\n",
        "                 \n",
        "    def forward(self, pow_seq, for_feat):\n",
        "        #print(np.shape(x))\n",
        "        x = torch.permute(pow_seq, (1,0,2) )  # permute batch with sequence \n",
        "        #print(np.shape(x))\n",
        "        x, (h, c) = self.lstm(x)\n",
        "\n",
        "        x = x[-1] # takes the last hidden state of LSTM\n",
        "        #print(x)\n",
        "        #print(np.shape(x))\n",
        "        # Dense layer\n",
        "        y = self.inputLay(for_feat)\n",
        "        y = F.elu(y) # F = nn.Functional\n",
        "        y = self.hidden_layer(y)\n",
        "        y = F.elu(y)\n",
        "        #print(y)\n",
        "        #print(np.shape(y))\n",
        "        z = torch.cat( (x,y), dim = 1 )\n",
        "        #print(np.shape(z))\n",
        "        z = self.combined(z)\n",
        "        z = F.elu(z)\n",
        "        z_expectation = self.output_lay_expectation(z)\n",
        "        z_variance = torch.sigmoid(self.output_lay_variance(z))\n",
        "\n",
        "        return z_expectation, z_variance\n",
        "  \n",
        "net = FFNN_LSTM()\n",
        "if torch.cuda.is_available():\n",
        "    print('##converting network to cuda-enabled')\n",
        "    net.cuda()\n",
        "\n",
        "print(net)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##converting network to cuda-enabled\n",
            "FFNN_LSTM(\n",
            "  (lstm): LSTM(1, 512)\n",
            "  (inputLay): Linear(in_features=16, out_features=512, bias=True)\n",
            "  (hidden_layer): Linear(in_features=512, out_features=512, bias=True)\n",
            "  (combined): Linear(in_features=1024, out_features=512, bias=True)\n",
            "  (output_lay_expectation): Linear(in_features=512, out_features=1, bias=True)\n",
            "  (output_lay_variance): Linear(in_features=512, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "johQwbAJ71Hm",
        "outputId": "eaf31ff0-b306-4648-cc68-b8b3a89c0b9f"
      },
      "source": [
        "myObj = FFNN_LSTM()\n",
        "pow_seq = torch.Tensor(np.array([[[0.3],[0.4],[0.6]],[[0.4],[0.5],[0.7]]]))\n",
        "for_feat = torch.Tensor([np.ones(16), np.ones(16)])\n",
        "myObj(pow_seq , for_feat)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[-0.0912],\n",
              "         [-0.0916]], grad_fn=<AddmmBackward0>), tensor([[0.5003],\n",
              "         [0.5003]], grad_fn=<SigmoidBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6L5Cnov8snwg"
      },
      "source": [
        "**Training of the LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18BzNXivuIvZ",
        "outputId": "3804db1c-3219-46eb-dcb3-f1baae328153"
      },
      "source": [
        "# Train loop \n",
        "criterion_MSE = nn.MSELoss() \n",
        "criterion_GNLLL = nn.GaussianNLLLoss()\n",
        "optimizer = optim.Adam(net.parameters(),lr=5e-6) # , momentum=0.9\n",
        "\n",
        "training_loss, validation_loss = [], []  # store loss for each epoch\n",
        "best_loss = 0 # for early stopping\n",
        "num_epochs = 500 # should be tuned\n",
        "\n",
        "for i in range(num_epochs):\n",
        "    boolean=0\n",
        "    # Track loss\n",
        "    epoch_training_loss = 0\n",
        "    epoch_validation_loss = 0\n",
        "    net.eval() # EVALUATION mode -> dont use regularization methods\n",
        "        \n",
        "    # For each sentence in validation set\n",
        "    for j,(inputs, targets) in enumerate(validation_set):\n",
        "\n",
        "        # Convert input to tensor\n",
        "        inputs_pow = torch.Tensor(inputs)\n",
        "        \n",
        "        # ADD (length-1) hours and not length because the first forecast (index 0) is already for the next hour after the first observation.\n",
        "        # The forecast in index (length-1) is then after the length first observations.\n",
        "        # A -1 was added because the training set of forecast has one less value.\n",
        "        \n",
        "        inputs_pred = torch.Tensor(x_train_sectors.iloc[(j*batch_size+length-1+int(len(complete_ts)*0.8)+1-1):((j+1)*batch_size+length-1+int(len(complete_ts)*0.8)+1-1)].values)        \n",
        "        # print('Inside training loop')\n",
        "        # print(f'shape of input {np.shape(inputs)}')\n",
        "\n",
        "        if len(inputs_pow) != batch_size:\n",
        "          inputs_pred = inputs_pred[:len(inputs_pow)]\n",
        "\n",
        "        # Convert target to tensor\n",
        "        targets = torch.Tensor(targets)\n",
        "        #print(targets)\n",
        "        # print(f'shape of targets {np.shape(targets)}')\n",
        "        \n",
        "        #Convert targets and inputs to cuda\n",
        "        if torch.cuda.is_available():\n",
        "            inputs_pow = Variable(inputs_pow.cuda())\n",
        "            inputs_pred = Variable(inputs_pred.cuda())\n",
        "            targets = Variable(targets.cuda())\n",
        "        \n",
        "        # Evaluate the model\n",
        "        outputs = net(inputs_pow,inputs_pred) \n",
        "\n",
        "        # print(f'shape of outputs {np.shape(outputs)}')\n",
        "        #print(outputs)\n",
        "        # Compute loss\n",
        "\n",
        "\n",
        "        loss_optimized =  criterion_GNLLL(outputs[0],targets,outputs[1]) \n",
        "        MSE = criterion_MSE(outputs[0],targets)\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "          epoch_validation_loss += MSE.cpu().detach().numpy()\n",
        "        else:\n",
        "          epoch_validation_loss += MSE.detach().numpy() # suma el loss de cada batch, luego se reinicia para proxima epoch\n",
        "    \n",
        "    \n",
        "    net.train()\n",
        "\n",
        "    for j,(inputs, targets) in enumerate(training_set):\n",
        "\n",
        "            # Convert input to tensor\n",
        "            inputs_pred = torch.Tensor(x_train_sectors.iloc[(j*batch_size+length-1):((j+1)*batch_size+length-1)].values)\n",
        "            inputs_pow = torch.Tensor(inputs)\n",
        "            # print('Inside training loop')\n",
        "            # print(f'shape of input {np.shape(inputs)}')\n",
        "\n",
        "            # Convert target to tensor\n",
        "            targets = torch.Tensor(targets)\n",
        "            #print(targets)\n",
        "            # print(f'shape of targets {np.shape(targets)}')\n",
        "\n",
        "            if len(inputs_pow) != batch_size:\n",
        "              inputs_pred = inputs_pred[:len(inputs_pow)]\n",
        "            \n",
        "            #Convert targets and inputs to cuda\n",
        "            if torch.cuda.is_available():\n",
        "                inputs_pow = Variable(inputs_pow.cuda())\n",
        "                inputs_pred = Variable(inputs_pred.cuda())\n",
        "                targets = Variable(targets.cuda())\n",
        "            \n",
        "            # Evaluate the model\n",
        "            outputs = net(inputs_pow,inputs_pred)      \n",
        "            # print(f'shape of outputs {np.shape(outputs)}')\n",
        "            #print(outputs)\n",
        "            # Compute loss\n",
        "            loss_optimized =  criterion_GNLLL(outputs[0],targets,outputs[1]) \n",
        "            MSE = criterion_MSE(outputs[0],targets)\n",
        "\n",
        "            optimizer.zero_grad() # zero the gradients\n",
        "            loss_optimized.backward()       # calculate gradients for current step\n",
        "            optimizer.step()      # update the weights \n",
        "\n",
        "            if torch.cuda.is_available():\n",
        "              epoch_training_loss += MSE.cpu().detach().numpy()\n",
        "            else:\n",
        "              epoch_training_loss += MSE.detach().numpy()\n",
        "\n",
        "    # Save loss for plot\n",
        "    training_loss.append(np.sqrt(epoch_training_loss/(len(training_set)-1)))\n",
        "    validation_loss.append(np.sqrt(epoch_validation_loss/(len(validation_set)-1)))       \n",
        "    print(f'Epoch {i}, training loss: {training_loss[-1]}, validation loss: {validation_loss[-1]}')\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, training loss: 0.06445897464911801, validation loss: 0.06692243253516167\n",
            "Epoch 1, training loss: 0.0644559778065298, validation loss: 0.06694600403650006\n",
            "Epoch 2, training loss: 0.06445413120998585, validation loss: 0.06694442379812567\n",
            "Epoch 3, training loss: 0.0644519410586468, validation loss: 0.0669403875612639\n",
            "Epoch 4, training loss: 0.06444963024050876, validation loss: 0.06693396840019755\n",
            "Epoch 5, training loss: 0.06444740046067414, validation loss: 0.06692749114104936\n",
            "Epoch 6, training loss: 0.06444533992874854, validation loss: 0.06692265600351957\n",
            "Epoch 7, training loss: 0.0644433986868028, validation loss: 0.06691999908645961\n",
            "Epoch 8, training loss: 0.06444151130915175, validation loss: 0.06691938410744026\n",
            "Epoch 9, training loss: 0.06443964161588876, validation loss: 0.06692036140792106\n",
            "Epoch 10, training loss: 0.06443775676889024, validation loss: 0.0669222709747415\n",
            "Epoch 11, training loss: 0.06443583909081646, validation loss: 0.06692435591316392\n",
            "Epoch 12, training loss: 0.064433876180364, validation loss: 0.06692601354641473\n",
            "Epoch 13, training loss: 0.06443187792466304, validation loss: 0.06692693853278094\n",
            "Epoch 14, training loss: 0.06442986137242482, validation loss: 0.0669271776633953\n",
            "Epoch 15, training loss: 0.06442784553511617, validation loss: 0.06692699001626401\n",
            "Epoch 16, training loss: 0.06442584344229649, validation loss: 0.06692668702956583\n",
            "Epoch 17, training loss: 0.0644238616416649, validation loss: 0.0669265140618589\n",
            "Epoch 18, training loss: 0.06442189584577196, validation loss: 0.06692659590782098\n",
            "Epoch 19, training loss: 0.06441993902626043, validation loss: 0.0669269540672176\n",
            "Epoch 20, training loss: 0.0644179888286283, validation loss: 0.06692752147881319\n",
            "Epoch 21, training loss: 0.06441603823099973, validation loss: 0.06692819161049662\n",
            "Epoch 22, training loss: 0.06441408599021575, validation loss: 0.06692886602857578\n",
            "Epoch 23, training loss: 0.06441213296080675, validation loss: 0.06692947639600878\n",
            "Epoch 24, training loss: 0.06441017734757949, validation loss: 0.06692999414792507\n",
            "Epoch 25, training loss: 0.06440822393480207, validation loss: 0.06693044112023717\n",
            "Epoch 26, training loss: 0.06440627209147794, validation loss: 0.06693083762049067\n",
            "Epoch 27, training loss: 0.06440432705374526, validation loss: 0.06693123938290504\n",
            "Epoch 28, training loss: 0.06440238578549877, validation loss: 0.06693166940622523\n",
            "Epoch 29, training loss: 0.06440044999126385, validation loss: 0.06693213786918822\n",
            "Epoch 30, training loss: 0.0643985184033556, validation loss: 0.06693265513064008\n",
            "Epoch 31, training loss: 0.06439658963398699, validation loss: 0.06693319526454423\n",
            "Epoch 32, training loss: 0.06439466533924207, validation loss: 0.06693375207996846\n",
            "Epoch 33, training loss: 0.06439274161327059, validation loss: 0.06693430899605624\n",
            "Epoch 34, training loss: 0.06439082060761189, validation loss: 0.06693486242241722\n",
            "Epoch 35, training loss: 0.06438890398269641, validation loss: 0.066935404074164\n",
            "Epoch 36, training loss: 0.06438699071158213, validation loss: 0.0669359409305137\n",
            "Epoch 37, training loss: 0.06438508009700565, validation loss: 0.0669364800313293\n",
            "Epoch 38, training loss: 0.06438317295957775, validation loss: 0.06693701907512098\n",
            "Epoch 39, training loss: 0.06438127025607887, validation loss: 0.06693756542505333\n",
            "Epoch 40, training loss: 0.06437937097657444, validation loss: 0.06693812281985802\n",
            "Epoch 41, training loss: 0.06437747803162247, validation loss: 0.06693867774048293\n",
            "Epoch 42, training loss: 0.0643755865302015, validation loss: 0.06693924535099897\n",
            "Epoch 43, training loss: 0.0643736989338836, validation loss: 0.06693981253886767\n",
            "Epoch 44, training loss: 0.06437181617735656, validation loss: 0.06694038896486552\n",
            "Epoch 45, training loss: 0.06436993795280188, validation loss: 0.06694095370551417\n",
            "Epoch 46, training loss: 0.06436806455554742, validation loss: 0.06694152545035865\n",
            "Epoch 47, training loss: 0.0643661945715366, validation loss: 0.06694209138307702\n",
            "Epoch 48, training loss: 0.06436432864893443, validation loss: 0.06694266138111238\n",
            "Epoch 49, training loss: 0.0643624662638392, validation loss: 0.06694322255452426\n",
            "Epoch 50, training loss: 0.0643606101357939, validation loss: 0.06694377974713357\n",
            "Epoch 51, training loss: 0.06435875815435393, validation loss: 0.06694433729035815\n",
            "Epoch 52, training loss: 0.06435691077203014, validation loss: 0.06694489093621321\n",
            "Epoch 53, training loss: 0.06435506861097913, validation loss: 0.06694544442585999\n",
            "Epoch 54, training loss: 0.06435323030630431, validation loss: 0.06694599315523536\n",
            "Epoch 55, training loss: 0.06435139757680697, validation loss: 0.06694654565997608\n",
            "Epoch 56, training loss: 0.06434957059829198, validation loss: 0.06694708787131118\n",
            "Epoch 57, training loss: 0.06434774572049766, validation loss: 0.06694763344387561\n",
            "Epoch 58, training loss: 0.06434592812617328, validation loss: 0.06694816629513113\n",
            "Epoch 59, training loss: 0.06434411349603839, validation loss: 0.0669487071935197\n",
            "Epoch 60, training loss: 0.0643423053959276, validation loss: 0.06694923020276301\n",
            "Epoch 61, training loss: 0.06434050159534144, validation loss: 0.06694976335527983\n",
            "Epoch 62, training loss: 0.06433870559173602, validation loss: 0.06695027788688178\n",
            "Epoch 63, training loss: 0.06433691126435542, validation loss: 0.06695079534039015\n",
            "Epoch 64, training loss: 0.06433512384862211, validation loss: 0.06695130722393325\n",
            "Epoch 65, training loss: 0.06433334314756602, validation loss: 0.06695180832019805\n",
            "Epoch 66, training loss: 0.06433156845265887, validation loss: 0.06695229518153516\n",
            "Epoch 67, training loss: 0.06432979562297292, validation loss: 0.06695278548130232\n",
            "Epoch 68, training loss: 0.06432803373123437, validation loss: 0.06695325969207949\n",
            "Epoch 69, training loss: 0.06432627405215287, validation loss: 0.06695372928425411\n",
            "Epoch 70, training loss: 0.0643245222221261, validation loss: 0.0669541905730581\n",
            "Epoch 71, training loss: 0.06432277410725573, validation loss: 0.0669546432055066\n",
            "Epoch 72, training loss: 0.06432103196811609, validation loss: 0.066955088597621\n",
            "Epoch 73, training loss: 0.06431929635043471, validation loss: 0.06695552573061182\n",
            "Epoch 74, training loss: 0.06431756386958357, validation loss: 0.06695596105568813\n",
            "Epoch 75, training loss: 0.06431583868877355, validation loss: 0.0669563822915844\n",
            "Epoch 76, training loss: 0.0643141187619887, validation loss: 0.06695679672090685\n",
            "Epoch 77, training loss: 0.06431240306017413, validation loss: 0.06695719794762468\n",
            "Epoch 78, training loss: 0.06431069412671257, validation loss: 0.06695759670030604\n",
            "Epoch 79, training loss: 0.06430898614306817, validation loss: 0.06695798587196901\n",
            "Epoch 80, training loss: 0.06430728723699715, validation loss: 0.06695837132452737\n",
            "Epoch 81, training loss: 0.0643055947651587, validation loss: 0.0669587403867726\n",
            "Epoch 82, training loss: 0.06430390955448272, validation loss: 0.06695909586266569\n",
            "Epoch 83, training loss: 0.06430222531530333, validation loss: 0.06695945024294628\n",
            "Epoch 84, training loss: 0.06430054942176477, validation loss: 0.06695979638152885\n",
            "Epoch 85, training loss: 0.06429887734084815, validation loss: 0.06696013801845149\n",
            "Epoch 86, training loss: 0.06429721363403751, validation loss: 0.06696046369830899\n",
            "Epoch 87, training loss: 0.06429555481084336, validation loss: 0.06696079437810754\n",
            "Epoch 88, training loss: 0.064293901364261, validation loss: 0.06696111073568374\n",
            "Epoch 89, training loss: 0.06429225397926708, validation loss: 0.06696141912799788\n",
            "Epoch 90, training loss: 0.06429061316354429, validation loss: 0.06696172089466307\n",
            "Epoch 91, training loss: 0.06428897835562986, validation loss: 0.06696200900933003\n",
            "Epoch 92, training loss: 0.06428734705935117, validation loss: 0.06696229306753582\n",
            "Epoch 93, training loss: 0.06428572425286852, validation loss: 0.06696257017454572\n",
            "Epoch 94, training loss: 0.06428410717403368, validation loss: 0.06696283943571608\n",
            "Epoch 95, training loss: 0.06428249410310201, validation loss: 0.06696310317906358\n",
            "Epoch 96, training loss: 0.06428088624543246, validation loss: 0.06696336221592643\n",
            "Epoch 97, training loss: 0.06427928361021776, validation loss: 0.0669636095831443\n",
            "Epoch 98, training loss: 0.06427768940026182, validation loss: 0.0669638449838992\n",
            "Epoch 99, training loss: 0.06427609838594248, validation loss: 0.06696407102632058\n",
            "Epoch 100, training loss: 0.0642745125833341, validation loss: 0.06696429706937462\n",
            "Epoch 101, training loss: 0.06427293489656333, validation loss: 0.06696451336435053\n",
            "Epoch 102, training loss: 0.06427136037598856, validation loss: 0.06696471906704848\n",
            "Epoch 103, training loss: 0.06426979266960099, validation loss: 0.06696492228490013\n",
            "Epoch 104, training loss: 0.06426822700333902, validation loss: 0.0669651257052969\n",
            "Epoch 105, training loss: 0.06426666867965548, validation loss: 0.06696532359639508\n",
            "Epoch 106, training loss: 0.06426511679468307, validation loss: 0.06696551180325111\n",
            "Epoch 107, training loss: 0.06426356943174093, validation loss: 0.06696569713288297\n",
            "Epoch 108, training loss: 0.06426202536403113, validation loss: 0.06696587485696506\n",
            "Epoch 109, training loss: 0.0642604878028938, validation loss: 0.06696604173507434\n",
            "Epoch 110, training loss: 0.06425895583176468, validation loss: 0.06696620803199638\n",
            "Epoch 111, training loss: 0.06425742830407331, validation loss: 0.06696637023584877\n",
            "Epoch 112, training loss: 0.06425590302749253, validation loss: 0.06696652026008118\n",
            "Epoch 113, training loss: 0.06425438303633631, validation loss: 0.06696667784772183\n",
            "Epoch 114, training loss: 0.06425286784479567, validation loss: 0.06696682178029348\n",
            "Epoch 115, training loss: 0.06425135939457924, validation loss: 0.06696696554553981\n",
            "Epoch 116, training loss: 0.06424985310023797, validation loss: 0.06696710665714131\n",
            "Epoch 117, training loss: 0.06424835165673286, validation loss: 0.06696724372320971\n",
            "Epoch 118, training loss: 0.06424685507105693, validation loss: 0.06696737701564301\n",
            "Epoch 119, training loss: 0.0642453623589056, validation loss: 0.06696750376822408\n",
            "Epoch 120, training loss: 0.0642438750113784, validation loss: 0.06696762101587114\n",
            "Epoch 121, training loss: 0.06424239186658397, validation loss: 0.06696773479399074\n",
            "Epoch 122, training loss: 0.06424091330999326, validation loss: 0.06696784855960658\n",
            "Epoch 123, training loss: 0.0642394397838551, validation loss: 0.06696795517719312\n",
            "Epoch 124, training loss: 0.06423797082527029, validation loss: 0.06696806081052742\n",
            "Epoch 125, training loss: 0.06423650468622298, validation loss: 0.06696815883718873\n",
            "Epoch 126, training loss: 0.06423504475184313, validation loss: 0.06696825528902083\n",
            "Epoch 127, training loss: 0.06423358840125293, validation loss: 0.0669683460797435\n",
            "Epoch 128, training loss: 0.06423213590560888, validation loss: 0.06696843817194756\n",
            "Epoch 129, training loss: 0.0642306853634123, validation loss: 0.06696852698200233\n",
            "Epoch 130, training loss: 0.06422924075841442, validation loss: 0.06696860320822579\n",
            "Epoch 131, training loss: 0.064227800848595, validation loss: 0.06696868087820756\n",
            "Epoch 132, training loss: 0.06422636474788516, validation loss: 0.0669687579410214\n",
            "Epoch 133, training loss: 0.064224932762088, validation loss: 0.06696883253407039\n",
            "Epoch 134, training loss: 0.06422350503108906, validation loss: 0.06696890584620796\n",
            "Epoch 135, training loss: 0.06422208082308757, validation loss: 0.06696897202547253\n",
            "Epoch 136, training loss: 0.06422066357822362, validation loss: 0.06696904122444693\n",
            "Epoch 137, training loss: 0.06421924972568525, validation loss: 0.06696910343887684\n",
            "Epoch 138, training loss: 0.06421783897181682, validation loss: 0.0669691610190098\n",
            "Epoch 139, training loss: 0.06421643368142282, validation loss: 0.06696921859846838\n",
            "Epoch 140, training loss: 0.06421503127747907, validation loss: 0.06696927409212444\n",
            "Epoch 141, training loss: 0.06421363528411557, validation loss: 0.06696931835373303\n",
            "Epoch 142, training loss: 0.06421224184789587, validation loss: 0.06696936719479793\n",
            "Epoch 143, training loss: 0.06421085221996382, validation loss: 0.06696941794275571\n",
            "Epoch 144, training loss: 0.06420946686161429, validation loss: 0.06696946270658989\n",
            "Epoch 145, training loss: 0.06420808704319048, validation loss: 0.06696950717634637\n",
            "Epoch 146, training loss: 0.06420670780576666, validation loss: 0.06696954770645643\n",
            "Epoch 147, training loss: 0.06420533406933815, validation loss: 0.06696958726093857\n",
            "Epoch 148, training loss: 0.06420396477948496, validation loss: 0.06696962831916875\n",
            "Epoch 149, training loss: 0.0642025977933735, validation loss: 0.06696966762763022\n",
            "Epoch 150, training loss: 0.06420123342494956, validation loss: 0.0669697057792731\n",
            "Epoch 151, training loss: 0.06419987402551107, validation loss: 0.06696974087913611\n",
            "Epoch 152, training loss: 0.06419851942328145, validation loss: 0.06696977547255904\n",
            "Epoch 153, training loss: 0.06419716709899626, validation loss: 0.06696981074285208\n",
            "Epoch 154, training loss: 0.06419581999050945, validation loss: 0.06696984557671241\n",
            "Epoch 155, training loss: 0.06419447292831192, validation loss: 0.06696988387955738\n",
            "Epoch 156, training loss: 0.06419313228787532, validation loss: 0.06696991485951742\n",
            "Epoch 157, training loss: 0.0641917946977369, validation loss: 0.06696994818670586\n",
            "Epoch 158, training loss: 0.064190458871536, validation loss: 0.0669699766829008\n",
            "Epoch 159, training loss: 0.0641891267491301, validation loss: 0.06697000574678304\n",
            "Epoch 160, training loss: 0.06418779775887606, validation loss: 0.06697003956330766\n",
            "Epoch 161, training loss: 0.06418647216372973, validation loss: 0.06697007394997186\n",
            "Epoch 162, training loss: 0.06418515105033726, validation loss: 0.06697010634439336\n",
            "Epoch 163, training loss: 0.06418383186926926, validation loss: 0.06697013842757014\n",
            "Epoch 164, training loss: 0.06418251668080913, validation loss: 0.066970170280528\n",
            "Epoch 165, training loss: 0.0641812051348626, validation loss: 0.06697019723469011\n",
            "Epoch 166, training loss: 0.06417989221391433, validation loss: 0.06697022616862791\n",
            "Epoch 167, training loss: 0.0641785850057034, validation loss: 0.06697025690660371\n",
            "Epoch 168, training loss: 0.06417728314845077, validation loss: 0.06697028674283217\n",
            "Epoch 169, training loss: 0.06417598240262844, validation loss: 0.06697031828476206\n",
            "Epoch 170, training loss: 0.06417468374464143, validation loss: 0.06697035251527338\n",
            "Epoch 171, training loss: 0.06417339035934981, validation loss: 0.06697038292996572\n",
            "Epoch 172, training loss: 0.06417210166439888, validation loss: 0.0669704125446627\n",
            "Epoch 173, training loss: 0.06417081421876329, validation loss: 0.06697044421184087\n",
            "Epoch 174, training loss: 0.06416953238563322, validation loss: 0.06697047434550786\n",
            "Epoch 175, training loss: 0.0641682517314181, validation loss: 0.06697050540338693\n",
            "Epoch 176, training loss: 0.06416697930693488, validation loss: 0.06697053820195345\n",
            "Epoch 177, training loss: 0.06416570986942242, validation loss: 0.0669705691754246\n",
            "Epoch 178, training loss: 0.06416444516394504, validation loss: 0.0669706040181177\n",
            "Epoch 179, training loss: 0.06416318247671311, validation loss: 0.06697063527031274\n",
            "Epoch 180, training loss: 0.06416192413278084, validation loss: 0.06697066818191702\n",
            "Epoch 181, training loss: 0.06416067154553447, validation loss: 0.06697070464738503\n",
            "Epoch 182, training loss: 0.0641594245667085, validation loss: 0.0669707411442016\n",
            "Epoch 183, training loss: 0.06415818017114187, validation loss: 0.06697077151685127\n",
            "Epoch 184, training loss: 0.06415694006462686, validation loss: 0.06697081160014456\n",
            "Epoch 185, training loss: 0.06415570210073714, validation loss: 0.0669708504825433\n",
            "Epoch 186, training loss: 0.06415446899900015, validation loss: 0.0669708947928703\n",
            "Epoch 187, training loss: 0.06415324271311537, validation loss: 0.06697093628353984\n",
            "Epoch 188, training loss: 0.06415201738535936, validation loss: 0.06697097645436163\n",
            "Epoch 189, training loss: 0.06415079757276988, validation loss: 0.06697101382769637\n",
            "Epoch 190, training loss: 0.06414958117367534, validation loss: 0.06697105909102291\n",
            "Epoch 191, training loss: 0.06414836868796374, validation loss: 0.06697110971018448\n",
            "Epoch 192, training loss: 0.06414716108887267, validation loss: 0.06697116223150014\n",
            "Epoch 193, training loss: 0.06414595797325072, validation loss: 0.06697121390774988\n",
            "Epoch 194, training loss: 0.06414475766982716, validation loss: 0.06697126871879694\n",
            "Epoch 195, training loss: 0.06414356158450002, validation loss: 0.06697132799123895\n",
            "Epoch 196, training loss: 0.06414237050033036, validation loss: 0.06697138021813559\n",
            "Epoch 197, training loss: 0.06414118127364238, validation loss: 0.06697144889000836\n",
            "Epoch 198, training loss: 0.06413999942285377, validation loss: 0.06697150884976351\n",
            "Epoch 199, training loss: 0.06413881926126792, validation loss: 0.06697157300140677\n",
            "Epoch 200, training loss: 0.06413764308424791, validation loss: 0.0669716406016965\n",
            "Epoch 201, training loss: 0.06413647032032212, validation loss: 0.06697170651902523\n",
            "Epoch 202, training loss: 0.06413530205334333, validation loss: 0.06697177322948512\n",
            "Epoch 203, training loss: 0.06413414086690224, validation loss: 0.06697184610154432\n",
            "Epoch 204, training loss: 0.06413297985367801, validation loss: 0.06697191738463618\n",
            "Epoch 205, training loss: 0.06413182512999484, validation loss: 0.06697199135645342\n",
            "Epoch 206, training loss: 0.06413067356719422, validation loss: 0.06697206472424454\n",
            "Epoch 207, training loss: 0.06412952765255511, validation loss: 0.06697213631594902\n",
            "Epoch 208, training loss: 0.06412838739545394, validation loss: 0.0669722094607164\n",
            "Epoch 209, training loss: 0.06412724999260375, validation loss: 0.06697228600740199\n",
            "Epoch 210, training loss: 0.06412612014774259, validation loss: 0.06697235949100976\n",
            "Epoch 211, training loss: 0.06412499302691456, validation loss: 0.06697243880343483\n",
            "Epoch 212, training loss: 0.06412387264071959, validation loss: 0.06697250980802409\n",
            "Epoch 213, training loss: 0.06412275547999487, validation loss: 0.0669725780274292\n",
            "Epoch 214, training loss: 0.06412164478677014, validation loss: 0.06697264140839863\n",
            "Epoch 215, training loss: 0.06412053991618114, validation loss: 0.06697270700473568\n",
            "Epoch 216, training loss: 0.06411943785418896, validation loss: 0.06697277680649663\n",
            "Epoch 217, training loss: 0.06411834064425649, validation loss: 0.06697284236875092\n",
            "Epoch 218, training loss: 0.06411725121712433, validation loss: 0.06697290775433805\n",
            "Epoch 219, training loss: 0.06411616297462716, validation loss: 0.06697297679292982\n",
            "Epoch 220, training loss: 0.06411507905409847, validation loss: 0.06697304350781051\n",
            "Epoch 221, training loss: 0.06411399876201516, validation loss: 0.06697311116491415\n",
            "Epoch 222, training loss: 0.06411292578103593, validation loss: 0.0669731689692537\n",
            "Epoch 223, training loss: 0.0641118550362229, validation loss: 0.06697322978811016\n",
            "Epoch 224, training loss: 0.0641107883891579, validation loss: 0.066973286239454\n",
            "Epoch 225, training loss: 0.06410972760755153, validation loss: 0.06697333712867712\n",
            "Epoch 226, training loss: 0.06410867254335458, validation loss: 0.06697338693858942\n",
            "Epoch 227, training loss: 0.06410761771068954, validation loss: 0.06697342735190107\n",
            "Epoch 228, training loss: 0.06410657213031895, validation loss: 0.066973463381205\n",
            "Epoch 229, training loss: 0.06410552695792306, validation loss: 0.06697349854860206\n",
            "Epoch 230, training loss: 0.06410448637298538, validation loss: 0.06697352644731148\n",
            "Epoch 231, training loss: 0.06410344914929006, validation loss: 0.06697354799221582\n",
            "Epoch 232, training loss: 0.06410241976191507, validation loss: 0.06697355909691491\n",
            "Epoch 233, training loss: 0.06410138837649597, validation loss: 0.06697356820688656\n",
            "Epoch 234, training loss: 0.06410036230074723, validation loss: 0.06697357024293504\n",
            "Epoch 235, training loss: 0.0640993433588754, validation loss: 0.06697356082081325\n",
            "Epoch 236, training loss: 0.06409832606683101, validation loss: 0.06697354988536344\n",
            "Epoch 237, training loss: 0.06409731132017242, validation loss: 0.0669735311334229\n",
            "Epoch 238, training loss: 0.06409630169303059, validation loss: 0.06697350225439946\n",
            "Epoch 239, training loss: 0.06409529647064104, validation loss: 0.06697346915813042\n",
            "Epoch 240, training loss: 0.06409429473074434, validation loss: 0.06697342936718818\n",
            "Epoch 241, training loss: 0.06409329493142528, validation loss: 0.0669733807740037\n",
            "Epoch 242, training loss: 0.06409230018765426, validation loss: 0.06697332658596805\n",
            "Epoch 243, training loss: 0.06409130853618418, validation loss: 0.0669732669411376\n",
            "Epoch 244, training loss: 0.06409031973044658, validation loss: 0.06697319897289321\n",
            "Epoch 245, training loss: 0.06408933285015567, validation loss: 0.06697312071017311\n",
            "Epoch 246, training loss: 0.06408835016305515, validation loss: 0.06697303548231483\n",
            "Epoch 247, training loss: 0.06408737028816891, validation loss: 0.06697294312760188\n",
            "Epoch 248, training loss: 0.06408639418715796, validation loss: 0.06697284329665174\n",
            "Epoch 249, training loss: 0.06408542021501412, validation loss: 0.06697273739357305\n",
            "Epoch 250, training loss: 0.06408444861979602, validation loss: 0.06697262133433125\n",
            "Epoch 251, training loss: 0.06408348040225423, validation loss: 0.0669724975677945\n",
            "Epoch 252, training loss: 0.0640825154322516, validation loss: 0.06697237106217153\n",
            "Epoch 253, training loss: 0.06408155340803902, validation loss: 0.06697222721804993\n",
            "Epoch 254, training loss: 0.06408059291287264, validation loss: 0.06697208364466113\n",
            "Epoch 255, training loss: 0.06407963433858042, validation loss: 0.06697193086148155\n",
            "Epoch 256, training loss: 0.06407867787181157, validation loss: 0.06697176671976615\n",
            "Epoch 257, training loss: 0.06407772424242149, validation loss: 0.06697160487680215\n",
            "Epoch 258, training loss: 0.06407677444423437, validation loss: 0.06697142512383494\n",
            "Epoch 259, training loss: 0.06407582208593834, validation loss: 0.0669712471358758\n",
            "Epoch 260, training loss: 0.06407487406331086, validation loss: 0.06697105679018416\n",
            "Epoch 261, training loss: 0.06407392783836205, validation loss: 0.06697086137535968\n",
            "Epoch 262, training loss: 0.06407298329026323, validation loss: 0.06697066305261454\n",
            "Epoch 263, training loss: 0.06407203826881705, validation loss: 0.06697045378318299\n",
            "Epoch 264, training loss: 0.06407109596278293, validation loss: 0.0669702339207449\n",
            "Epoch 265, training loss: 0.06407015374896197, validation loss: 0.06697000929813786\n",
            "Epoch 266, training loss: 0.06406921207612101, validation loss: 0.06696976823991233\n",
            "Epoch 267, training loss: 0.0640682688281418, validation loss: 0.06696952367382601\n",
            "Epoch 268, training loss: 0.06406733166444475, validation loss: 0.06696926952146418\n",
            "Epoch 269, training loss: 0.0640663905417352, validation loss: 0.06696900935930836\n",
            "Epoch 270, training loss: 0.0640654535264051, validation loss: 0.06696873628574147\n",
            "Epoch 271, training loss: 0.06406451550676914, validation loss: 0.06696845897187041\n",
            "Epoch 272, training loss: 0.0640635750484747, validation loss: 0.06696817818830166\n",
            "Epoch 273, training loss: 0.06406263476407015, validation loss: 0.06696788471676603\n",
            "Epoch 274, training loss: 0.06406169583704496, validation loss: 0.06696758639283992\n",
            "Epoch 275, training loss: 0.06406075423295497, validation loss: 0.06696728262648953\n",
            "Epoch 276, training loss: 0.06405981497209368, validation loss: 0.06696697537248567\n",
            "Epoch 277, training loss: 0.0640588705456822, validation loss: 0.0669666641802851\n",
            "Epoch 278, training loss: 0.06405792529295908, validation loss: 0.06696634314368685\n",
            "Epoch 279, training loss: 0.06405698099271136, validation loss: 0.0669660191063436\n",
            "Epoch 280, training loss: 0.06405603387436246, validation loss: 0.06696568596220139\n",
            "Epoch 281, training loss: 0.06405508747550588, validation loss: 0.06696534824824438\n",
            "Epoch 282, training loss: 0.06405413647347989, validation loss: 0.06696500291092958\n",
            "Epoch 283, training loss: 0.06405318686805495, validation loss: 0.0669646568008634\n",
            "Epoch 284, training loss: 0.06405223304067957, validation loss: 0.0669642937630639\n",
            "Epoch 285, training loss: 0.06405128040367883, validation loss: 0.06696393139284858\n",
            "Epoch 286, training loss: 0.06405032131793967, validation loss: 0.06696356409882542\n",
            "Epoch 287, training loss: 0.06404936181288531, validation loss: 0.06696319105586888\n",
            "Epoch 288, training loss: 0.06404840094608708, validation loss: 0.0669628195073841\n",
            "Epoch 289, training loss: 0.06404743559390932, validation loss: 0.06696244093658953\n",
            "Epoch 290, training loss: 0.06404647148381246, validation loss: 0.06696204918977781\n",
            "Epoch 291, training loss: 0.06404550054345001, validation loss: 0.06696166161434211\n",
            "Epoch 292, training loss: 0.06404452841562981, validation loss: 0.06696126880208571\n",
            "Epoch 293, training loss: 0.06404355294349673, validation loss: 0.0669608738947607\n",
            "Epoch 294, training loss: 0.0640425760995551, validation loss: 0.06696047090552473\n",
            "Epoch 295, training loss: 0.06404159520911934, validation loss: 0.06696007057666556\n",
            "Epoch 296, training loss: 0.06404061041176001, validation loss: 0.0669596650647286\n",
            "Epoch 297, training loss: 0.06403962279963323, validation loss: 0.0669592582962594\n",
            "Epoch 298, training loss: 0.06403863146085402, validation loss: 0.0669588478376061\n",
            "Epoch 299, training loss: 0.06403763675444908, validation loss: 0.06695844175069575\n",
            "Epoch 300, training loss: 0.06403663733380477, validation loss: 0.06695803175598572\n",
            "Epoch 301, training loss: 0.06403563488151395, validation loss: 0.06695761768536496\n",
            "Epoch 302, training loss: 0.06403462996808575, validation loss: 0.06695720505854688\n",
            "Epoch 303, training loss: 0.06403362069863922, validation loss: 0.06695679709244777\n",
            "Epoch 304, training loss: 0.06403260590242824, validation loss: 0.06695638763027341\n",
            "Epoch 305, training loss: 0.06403158856795366, validation loss: 0.06695597198301047\n",
            "Epoch 306, training loss: 0.06403056663429449, validation loss: 0.0669555682865725\n",
            "Epoch 307, training loss: 0.06402953884817508, validation loss: 0.06695515124652517\n",
            "Epoch 308, training loss: 0.06402850974041747, validation loss: 0.06695474327259948\n",
            "Epoch 309, training loss: 0.06402747767622079, validation loss: 0.06695432851313901\n",
            "Epoch 310, training loss: 0.06402643772591415, validation loss: 0.06695392600711174\n",
            "Epoch 311, training loss: 0.06402539538846047, validation loss: 0.06695351003023974\n",
            "Epoch 312, training loss: 0.06402434967361655, validation loss: 0.06695310177267386\n",
            "Epoch 313, training loss: 0.06402330011490115, validation loss: 0.06695269363010467\n",
            "Epoch 314, training loss: 0.06402224683542235, validation loss: 0.06695228312489303\n",
            "Epoch 315, training loss: 0.06402118784772336, validation loss: 0.06695187773034272\n",
            "Epoch 316, training loss: 0.06402012552512336, validation loss: 0.06695147153648426\n",
            "Epoch 317, training loss: 0.06401906173596425, validation loss: 0.06695106109726476\n",
            "Epoch 318, training loss: 0.06401799105230688, validation loss: 0.06695065658793668\n",
            "Epoch 319, training loss: 0.06401691525628316, validation loss: 0.06695025231531251\n",
            "Epoch 320, training loss: 0.06401583702277808, validation loss: 0.06694984625127333\n",
            "Epoch 321, training loss: 0.0640147546536663, validation loss: 0.06694945061906304\n",
            "Epoch 322, training loss: 0.06401366549393513, validation loss: 0.06694905068988069\n",
            "Epoch 323, training loss: 0.06401257449694217, validation loss: 0.06694865375031318\n",
            "Epoch 324, training loss: 0.06401147709336832, validation loss: 0.06694826392101419\n",
            "Epoch 325, training loss: 0.06401037792849822, validation loss: 0.06694786973804048\n",
            "Epoch 326, training loss: 0.06400927048740762, validation loss: 0.06694747816725045\n",
            "Epoch 327, training loss: 0.06400816205538636, validation loss: 0.06694709215646565\n",
            "Epoch 328, training loss: 0.06400704728938351, validation loss: 0.06694670789623662\n",
            "Epoch 329, training loss: 0.06400592920955747, validation loss: 0.06694632801166554\n",
            "Epoch 330, training loss: 0.06400480870851984, validation loss: 0.06694595102940364\n",
            "Epoch 331, training loss: 0.06400368353217499, validation loss: 0.06694557906720476\n",
            "Epoch 332, training loss: 0.0640025573240689, validation loss: 0.06694520336469519\n",
            "Epoch 333, training loss: 0.06400142413419085, validation loss: 0.06694484288589224\n",
            "Epoch 334, training loss: 0.06400028971469551, validation loss: 0.06694448025217309\n",
            "Epoch 335, training loss: 0.06399914992257628, validation loss: 0.06694412095309392\n",
            "Epoch 336, training loss: 0.06399800658874072, validation loss: 0.0669437658323293\n",
            "Epoch 337, training loss: 0.0639968606033473, validation loss: 0.06694341096408536\n",
            "Epoch 338, training loss: 0.06399570892523622, validation loss: 0.0669430566112529\n",
            "Epoch 339, training loss: 0.0639945554221964, validation loss: 0.06694271460868192\n",
            "Epoch 340, training loss: 0.06399339905503966, validation loss: 0.0669423745257113\n",
            "Epoch 341, training loss: 0.06399223859162746, validation loss: 0.0669420355899932\n",
            "Epoch 342, training loss: 0.06399107609070814, validation loss: 0.06694170295569697\n",
            "Epoch 343, training loss: 0.06398990713825872, validation loss: 0.06694137645848319\n",
            "Epoch 344, training loss: 0.06398873849935494, validation loss: 0.06694105537589823\n",
            "Epoch 345, training loss: 0.0639875660672437, validation loss: 0.06694073793138902\n",
            "Epoch 346, training loss: 0.06398638810932049, validation loss: 0.06694043400817475\n",
            "Epoch 347, training loss: 0.06398520769536416, validation loss: 0.0669401309383125\n",
            "Epoch 348, training loss: 0.06398402922341268, validation loss: 0.06693982945397713\n",
            "Epoch 349, training loss: 0.063982842518972, validation loss: 0.06693953859006418\n",
            "Epoch 350, training loss: 0.06398165464401129, validation loss: 0.06693925728297719\n",
            "Epoch 351, training loss: 0.06398046414546989, validation loss: 0.06693897708177132\n",
            "Epoch 352, training loss: 0.06397927124511789, validation loss: 0.06693870724827848\n",
            "Epoch 353, training loss: 0.06397807329195852, validation loss: 0.06693844615416011\n",
            "Epoch 354, training loss: 0.06397687305935612, validation loss: 0.0669381876124989\n",
            "Epoch 355, training loss: 0.06397567162315994, validation loss: 0.06693793772325995\n",
            "Epoch 356, training loss: 0.06397446547856082, validation loss: 0.06693769287207864\n",
            "Epoch 357, training loss: 0.06397325941974455, validation loss: 0.0669374608211745\n",
            "Epoch 358, training loss: 0.06397205013326719, validation loss: 0.06693722898323629\n",
            "Epoch 359, training loss: 0.06397083897144519, validation loss: 0.06693700572691141\n",
            "Epoch 360, training loss: 0.06396962874793277, validation loss: 0.06693678797362185\n",
            "Epoch 361, training loss: 0.06396841092502167, validation loss: 0.06693657594029888\n",
            "Epoch 362, training loss: 0.06396719302813876, validation loss: 0.06693637336733883\n",
            "Epoch 363, training loss: 0.06396597461634139, validation loss: 0.0669361785894014\n",
            "Epoch 364, training loss: 0.06396475327403608, validation loss: 0.06693599389453185\n",
            "Epoch 365, training loss: 0.06396353084253162, validation loss: 0.06693581806293385\n",
            "Epoch 366, training loss: 0.06396230510730438, validation loss: 0.06693565373823603\n",
            "Epoch 367, training loss: 0.06396107620768994, validation loss: 0.06693549316842652\n",
            "Epoch 368, training loss: 0.06395984989783836, validation loss: 0.0669353427928124\n",
            "Epoch 369, training loss: 0.06395861636635973, validation loss: 0.06693519976454973\n",
            "Epoch 370, training loss: 0.06395738626375914, validation loss: 0.06693507251202922\n",
            "Epoch 371, training loss: 0.06395615271989245, validation loss: 0.06693494954776194\n",
            "Epoch 372, training loss: 0.06395492049188017, validation loss: 0.06693484413859647\n",
            "Epoch 373, training loss: 0.06395368572730897, validation loss: 0.06693474293668436\n",
            "Epoch 374, training loss: 0.06395244790412198, validation loss: 0.06693464748471864\n",
            "Epoch 375, training loss: 0.06395121137193677, validation loss: 0.06693456906601092\n",
            "Epoch 376, training loss: 0.06394997041079316, validation loss: 0.06693450120408169\n",
            "Epoch 377, training loss: 0.06394873091672473, validation loss: 0.06693444359045443\n",
            "Epoch 378, training loss: 0.0639474901948906, validation loss: 0.06693439886175119\n",
            "Epoch 379, training loss: 0.06394624752221434, validation loss: 0.06693436260174568\n",
            "Epoch 380, training loss: 0.06394500601369424, validation loss: 0.06693433666649773\n",
            "Epoch 381, training loss: 0.06394376374764066, validation loss: 0.0669343179573498\n",
            "Epoch 382, training loss: 0.06394251916587038, validation loss: 0.06693431458485953\n",
            "Epoch 383, training loss: 0.06394127523355812, validation loss: 0.06693432024053887\n",
            "Epoch 384, training loss: 0.06394002978167154, validation loss: 0.06693433628472457\n",
            "Epoch 385, training loss: 0.06393878139327765, validation loss: 0.06693436108329195\n",
            "Epoch 386, training loss: 0.06393753747699182, validation loss: 0.06693439790024393\n",
            "Epoch 387, training loss: 0.06393629071607662, validation loss: 0.06693444362069363\n",
            "Epoch 388, training loss: 0.06393504183859515, validation loss: 0.06693450217652859\n",
            "Epoch 389, training loss: 0.06393379576674672, validation loss: 0.06693456605339168\n",
            "Epoch 390, training loss: 0.06393254632170527, validation loss: 0.06693464428516645\n",
            "Epoch 391, training loss: 0.06393129775755557, validation loss: 0.06693472755487562\n",
            "Epoch 392, training loss: 0.06393004790056554, validation loss: 0.06693481898424818\n",
            "Epoch 393, training loss: 0.06392879855155317, validation loss: 0.06693492302034072\n",
            "Epoch 394, training loss: 0.06392754797452095, validation loss: 0.066935033312293\n",
            "Epoch 395, training loss: 0.06392629631979309, validation loss: 0.06693515336278288\n",
            "Epoch 396, training loss: 0.06392504328242896, validation loss: 0.06693528729193803\n",
            "Epoch 397, training loss: 0.06392379353071181, validation loss: 0.0669354283405942\n",
            "Epoch 398, training loss: 0.06392253847371608, validation loss: 0.0669355747506318\n",
            "Epoch 399, training loss: 0.06392129078482375, validation loss: 0.06693573113693783\n",
            "Epoch 400, training loss: 0.0639200382645395, validation loss: 0.06693590306192784\n",
            "Epoch 401, training loss: 0.06391878705651494, validation loss: 0.06693607826715171\n",
            "Epoch 402, training loss: 0.06391753678949401, validation loss: 0.06693626668267214\n",
            "Epoch 403, training loss: 0.06391628414027364, validation loss: 0.06693646396248318\n",
            "Epoch 404, training loss: 0.06391503553388794, validation loss: 0.06693666670783521\n",
            "Epoch 405, training loss: 0.0639137844908136, validation loss: 0.06693687956775042\n",
            "Epoch 406, training loss: 0.06391253521763397, validation loss: 0.0669371032659063\n",
            "Epoch 407, training loss: 0.06391128504335393, validation loss: 0.06693733167167427\n",
            "Epoch 408, training loss: 0.06391003464184514, validation loss: 0.06693757230489049\n",
            "Epoch 409, training loss: 0.06390878599804438, validation loss: 0.06693782385948269\n",
            "Epoch 410, training loss: 0.06390753805584287, validation loss: 0.06693807698548274\n",
            "Epoch 411, training loss: 0.06390628845041942, validation loss: 0.06693834223526132\n",
            "Epoch 412, training loss: 0.06390503902268888, validation loss: 0.06693861524761344\n",
            "Epoch 413, training loss: 0.06390378857936191, validation loss: 0.06693889583481094\n",
            "Epoch 414, training loss: 0.06390254268236299, validation loss: 0.06693918358629727\n",
            "Epoch 415, training loss: 0.06390129304144519, validation loss: 0.06693947914376976\n",
            "Epoch 416, training loss: 0.06390004345586751, validation loss: 0.06693978222568947\n",
            "Epoch 417, training loss: 0.06389879396814524, validation loss: 0.06694008919642928\n",
            "Epoch 418, training loss: 0.06389754371827994, validation loss: 0.06694040841915426\n",
            "Epoch 419, training loss: 0.06389629719046482, validation loss: 0.06694072989937377\n",
            "Epoch 420, training loss: 0.06389504536623088, validation loss: 0.06694106075421437\n",
            "Epoch 421, training loss: 0.06389379728580351, validation loss: 0.06694140063151928\n",
            "Epoch 422, training loss: 0.06389254556426573, validation loss: 0.06694174707029034\n",
            "Epoch 423, training loss: 0.06389129686134377, validation loss: 0.06694209665937109\n",
            "Epoch 424, training loss: 0.06389004678947782, validation loss: 0.06694245616704467\n",
            "Epoch 425, training loss: 0.06388879417592262, validation loss: 0.06694281789388236\n",
            "Epoch 426, training loss: 0.06388754436986503, validation loss: 0.06694318958719951\n",
            "Epoch 427, training loss: 0.06388629217015401, validation loss: 0.06694357011608816\n",
            "Epoch 428, training loss: 0.0638850402693675, validation loss: 0.0669439563035447\n",
            "Epoch 429, training loss: 0.06388378940748805, validation loss: 0.06694434519800112\n",
            "Epoch 430, training loss: 0.06388253917310753, validation loss: 0.06694473698927741\n",
            "Epoch 431, training loss: 0.06388128594642782, validation loss: 0.06694514410542066\n",
            "Epoch 432, training loss: 0.06388003433155885, validation loss: 0.06694554751329582\n",
            "Epoch 433, training loss: 0.06387878091443618, validation loss: 0.06694596040046501\n",
            "Epoch 434, training loss: 0.0638775290496669, validation loss: 0.06694637844724559\n",
            "Epoch 435, training loss: 0.06387627767871605, validation loss: 0.06694679924277948\n",
            "Epoch 436, training loss: 0.06387502361596988, validation loss: 0.06694722880646764\n",
            "Epoch 437, training loss: 0.06387377060089977, validation loss: 0.06694766602819004\n",
            "Epoch 438, training loss: 0.0638725162381303, validation loss: 0.06694810552082692\n",
            "Epoch 439, training loss: 0.06387126083732496, validation loss: 0.06694854822415583\n",
            "Epoch 440, training loss: 0.06387000598022097, validation loss: 0.06694899705682243\n",
            "Epoch 441, training loss: 0.06386875170069352, validation loss: 0.06694945692051255\n",
            "Epoch 442, training loss: 0.06386749623851662, validation loss: 0.0669499134027659\n",
            "Epoch 443, training loss: 0.06386623905786737, validation loss: 0.06695038364198043\n",
            "Epoch 444, training loss: 0.06386498499979155, validation loss: 0.06695085149760219\n",
            "Epoch 445, training loss: 0.06386372901578229, validation loss: 0.06695132292755261\n",
            "Epoch 446, training loss: 0.06386247459014628, validation loss: 0.0669518089415452\n",
            "Epoch 447, training loss: 0.06386121998469424, validation loss: 0.06695228941682534\n",
            "Epoch 448, training loss: 0.06385996480154747, validation loss: 0.06695277675945263\n",
            "Epoch 449, training loss: 0.0638587073120808, validation loss: 0.06695326852254886\n",
            "Epoch 450, training loss: 0.06385745269918232, validation loss: 0.06695376476948814\n",
            "Epoch 451, training loss: 0.06385619722621583, validation loss: 0.06695426399433552\n",
            "Epoch 452, training loss: 0.06385493832897315, validation loss: 0.06695477002309114\n",
            "Epoch 453, training loss: 0.06385368567778155, validation loss: 0.06695528031202733\n",
            "Epoch 454, training loss: 0.06385242850902668, validation loss: 0.06695579581738204\n",
            "Epoch 455, training loss: 0.06385117320278012, validation loss: 0.06695631435995046\n",
            "Epoch 456, training loss: 0.06384991407786861, validation loss: 0.06695684187190706\n",
            "Epoch 457, training loss: 0.0638486592509651, validation loss: 0.06695736507209668\n",
            "Epoch 458, training loss: 0.06384740174642008, validation loss: 0.06695789771197282\n",
            "Epoch 459, training loss: 0.06384614422674317, validation loss: 0.06695843606958583\n",
            "Epoch 460, training loss: 0.06384488631057302, validation loss: 0.06695897553168631\n",
            "Epoch 461, training loss: 0.06384362913566763, validation loss: 0.06695952235198098\n",
            "Epoch 462, training loss: 0.0638423704642839, validation loss: 0.06696006836823096\n",
            "Epoch 463, training loss: 0.06384111035543752, validation loss: 0.06696061920097322\n",
            "Epoch 464, training loss: 0.0638398511821237, validation loss: 0.06696117481247683\n",
            "Epoch 465, training loss: 0.06383859181194766, validation loss: 0.06696173034642788\n",
            "Epoch 466, training loss: 0.06383733492461782, validation loss: 0.06696228720943939\n",
            "Epoch 467, training loss: 0.0638360757072998, validation loss: 0.0669628461360458\n",
            "Epoch 468, training loss: 0.06383481440681503, validation loss: 0.06696340917518182\n",
            "Epoch 469, training loss: 0.06383355585826728, validation loss: 0.06696397913882196\n",
            "Epoch 470, training loss: 0.06383229413575733, validation loss: 0.06696455035297351\n",
            "Epoch 471, training loss: 0.06383103480653318, validation loss: 0.0669651269567846\n",
            "Epoch 472, training loss: 0.06382977427885617, validation loss: 0.06696570391149949\n",
            "Epoch 473, training loss: 0.0638285133047632, validation loss: 0.0669662811012664\n",
            "Epoch 474, training loss: 0.06382725146630164, validation loss: 0.06696686780081768\n",
            "Epoch 475, training loss: 0.0638259889738239, validation loss: 0.06696745286509051\n",
            "Epoch 476, training loss: 0.06382472959469664, validation loss: 0.0669680373324358\n",
            "Epoch 477, training loss: 0.0638234662158452, validation loss: 0.06696863381992232\n",
            "Epoch 478, training loss: 0.06382220555427402, validation loss: 0.0669692255582465\n",
            "Epoch 479, training loss: 0.06382094230931216, validation loss: 0.06696982333882583\n",
            "Epoch 480, training loss: 0.06381967779534381, validation loss: 0.06697041823838926\n",
            "Epoch 481, training loss: 0.06381841575996007, validation loss: 0.06697102300479682\n",
            "Epoch 482, training loss: 0.06381715135660063, validation loss: 0.06697161741949717\n",
            "Epoch 483, training loss: 0.06381588913411873, validation loss: 0.06697222708184201\n",
            "Epoch 484, training loss: 0.06381462053527533, validation loss: 0.06697283169684931\n",
            "Epoch 485, training loss: 0.06381335546659501, validation loss: 0.06697343753586121\n",
            "Epoch 486, training loss: 0.06381209093093378, validation loss: 0.06697404461094032\n",
            "Epoch 487, training loss: 0.06381082336524113, validation loss: 0.06697465120724805\n",
            "Epoch 488, training loss: 0.06380955555675145, validation loss: 0.06697525987236598\n",
            "Epoch 489, training loss: 0.06380828738012877, validation loss: 0.0669758697418763\n",
            "Epoch 490, training loss: 0.06380701971944659, validation loss: 0.0669764821208494\n",
            "Epoch 491, training loss: 0.06380575158755264, validation loss: 0.06697709483503615\n",
            "Epoch 492, training loss: 0.06380448002808034, validation loss: 0.06697770249083052\n",
            "Epoch 493, training loss: 0.0638032105510116, validation loss: 0.06697830923173925\n",
            "Epoch 494, training loss: 0.06380194018473248, validation loss: 0.06697891789681251\n",
            "Epoch 495, training loss: 0.06380066779586467, validation loss: 0.0669795272364922\n",
            "Epoch 496, training loss: 0.06379939602967327, validation loss: 0.06698013700122758\n",
            "Epoch 497, training loss: 0.06379812315288001, validation loss: 0.06698074543845509\n",
            "Epoch 498, training loss: 0.06379685058881883, validation loss: 0.06698135770426271\n",
            "Epoch 499, training loss: 0.06379557630796615, validation loss: 0.06698196669725533\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0KwpxZBKifo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "971903d6-74f7-431f-8d00-7a7796948708"
      },
      "source": [
        "# Plot training and validation loss\n",
        "epoch = np.arange(len(training_loss))\n",
        "plt.figure()\n",
        "plt.plot(epoch, training_loss, epoch, validation_loss)\n",
        "plt.xlabel('Epoch'), plt.ylabel('RMSE')\n",
        "plt.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWoC-AIgt85y"
      },
      "source": [
        "**Evaluation of LSTM 1 to 6 hours ahead, on validation set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qymy0x2t2cU-"
      },
      "source": [
        "# Define the validation set as one sequence\n",
        "validation_power = input_generator[int(len(input_generator)*0.8)+1 : int(len(input_generator))-1]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jqs_USuF4Y-2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "bef7a32f-5fc3-46e3-9466-331effceab19"
      },
      "source": [
        "# Define slices of 24h inputs and corresponding targets 1, 2 and 3 hours ahead\n",
        "p_inputs = []\n",
        "p_targets1h = []\n",
        "p_targets2h = []\n",
        "p_targets3h = []\n",
        "p_targets4h = []\n",
        "p_targets5h = []\n",
        "p_targets6h = []\n",
        "for i in range(len(validation_power)-(length+2)):\n",
        "  p_inputs.append(validation_power[i:i+length])\n",
        "  p_targets1h.append(validation_power[i+length])\n",
        "  p_targets2h.append(validation_power[i+length+1])\n",
        "  p_targets3h.append(validation_power[i+length+2])\n",
        "  p_targets4h.append(validation_power[i+length+3])\n",
        "  p_targets5h.append(validation_power[i+length+4])\n",
        "  p_targets6h.append(validation_power[i+length+5])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-932979844631>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0mp_targets4h\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_power\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mp_targets5h\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_power\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m   \u001b[0mp_targets6h\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_power\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: index 2634 is out of bounds for axis 0 with size 2634"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vt1KrXX0uHx5"
      },
      "source": [
        "# Forecasting 1, 2 and 3 hours ahead\n",
        "\n",
        "# Back on CPU\n",
        "net.to('cpu')\n",
        "\n",
        "# Store predictions and errors\n",
        "pred_1h = []\n",
        "err_1h = []\n",
        "pred_2h = []\n",
        "err_2h = []\n",
        "pred_3h = []\n",
        "err_3h = []\n",
        "pred_4h = []\n",
        "err_4h = []\n",
        "pred_5h = []\n",
        "err_5h = []\n",
        "pred_6h = []\n",
        "err_6h = []\n",
        "\n",
        "# Loop over the sequences of valid data\n",
        "for seq in range(len(p_inputs)):\n",
        "\n",
        "    # Define past value for the 1h forecast\n",
        "    past = p_inputs[seq]\n",
        "    \n",
        "    # Take output for the past sequence\n",
        "    pred_1h.append(net(torch.Tensor([past])).item())\n",
        "    err_1h.append(pred_1h[-1]-p_targets1h[seq][0])\n",
        "\n",
        "    # Repeat with prediction 2 hours ahead actualizing the past values\n",
        "    past = np.append(past,[[pred_1h[-1]]],0)\n",
        "    pred_2h.append(net(torch.Tensor([past])).item())\n",
        "    err_2h.append(pred_2h[-1]-p_targets2h[seq][0])\n",
        "\n",
        "    # Repeat with prediction 3 hours ahead\n",
        "    past = np.append(past,[[pred_2h[-1]]],0)\n",
        "    pred_3h.append(net(torch.Tensor([past])).item())\n",
        "    err_3h.append(pred_3h[-1]-p_targets3h[seq][0])\n",
        "\n",
        "    # Repeat with prediction 4 hours ahead\n",
        "    past = np.append(past,[[pred_3h[-1]]],0)\n",
        "    pred_4h.append(net(torch.Tensor([past])).item())\n",
        "    err_4h.append(pred_4h[-1]-p_targets4h[seq][0])\n",
        "\n",
        "    # Repeat with prediction 5 hours ahead\n",
        "    past = np.append(past,[[pred_4h[-1]]],0)\n",
        "    pred_5h.append(net(torch.Tensor([past])).item())\n",
        "    err_5h.append(pred_5h[-1]-p_targets5h[seq][0])\n",
        "\n",
        "    # Repeat with prediction 6 hours ahead\n",
        "    past = np.append(past,[[pred_5h[-1]]],0)\n",
        "    pred_6h.append(net(torch.Tensor([past])).item())\n",
        "    err_6h.append(pred_6h[-1]-p_targets6h[seq][0])\n",
        "\n",
        "    if seq % 100 == 0:\n",
        "      print(f'step {seq+1}, RMSE 1h: {np.sqrt(stat.mean(err_1h[n]**2 for n in range(len(err_1h))))}, RMSE 2h: {np.sqrt(stat.mean(err_2h[n]**2 for n in range(len(err_2h))))}, RMSE 3h: {np.sqrt(stat.mean(err_3h[n]**2 for n in range(len(err_3h))))}, RMSE 4h: {np.sqrt(stat.mean(err_4h[n]**2 for n in range(len(err_4h))))}, RMSE 5h: {np.sqrt(stat.mean(err_5h[n]**2 for n in range(len(err_5h))))}, RMSE 6h: {np.sqrt(stat.mean(err_6h[n]**2 for n in range(len(err_6h))))}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_EjqAInudl4"
      },
      "source": [
        "# Estimation of confidence intervals:\n",
        "RMSE_1h = np.sqrt(stat.mean(err_1h[n]**2 for n in range(len(err_1h))))\n",
        "RMSE_2h = np.sqrt(stat.mean(err_2h[n]**2 for n in range(len(err_2h))))\n",
        "RMSE_3h = np.sqrt(stat.mean(err_3h[n]**2 for n in range(len(err_3h))))\n",
        "CI_1h = [norm.ppf(0.025)*RMSE_1h,norm.ppf(0.975)*RMSE_1h]\n",
        "CI_2h = [norm.ppf(0.025)*RMSE_2h,norm.ppf(0.975)*RMSE_2h]\n",
        "CI_3h = [norm.ppf(0.025)*RMSE_3h,norm.ppf(0.975)*RMSE_3h]\n",
        "print(f'Confidence interval 1h: {CI_1h}')\n",
        "print(f'Confidence interval 2h: {CI_2h}')\n",
        "print(f'Confidence interval 3h: {CI_3h}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLu4ID92DPVF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2gZs4I3NZ_a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}